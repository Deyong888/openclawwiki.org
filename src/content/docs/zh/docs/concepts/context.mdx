---
title: 上下文 (Context)
description: OpenClaw 如何构建 LLM 的提示上下文。
sidebar:
  order: 5
---

**上下文 (Context)** 是单次推理发送给 LLM 的完整信息集。它是 AI 在那一刻看到的“世界”。

## 上下文的组成部分

典型的上下文由多个层构建，从一般到具体排序：

### 1. 系统提示 (System Prompt / The Persona)
*   **角色**：定义 Agent 是谁。
*   **内容**：“你是 OpenClaw，一个有用的 AI 助手。你回答简洁...”
*   **优先级**：高。这设定了行为基准。

### 2. 世界状态 / 环境 (World State / Environment)
*   **时间**：“当前日期：2023-10-27”。
*   **用户信息**：“用户名：Alice。位置：纽约。”
*   **操作系统/平台**：“运行在 Linux 上。渠道：Telegram。”

### 3. 技能定义 (Skill Definitions / Tools)
*   **Schema**：可用函数的 JSON 描述（例如 `web_search`, `read_file`）。
*   **指令**：“如果用户询问时事，请使用 `web_search`。”

### 4. 长期记忆 (Long-Term Memory / RAG)
*   **检索**：根据用户最新的查询从向量数据库中提取的相关片段。
*   **内容**：“Alice 在之前的聊天中提到她喜欢寿司。”

### 5. 对话历史 (Conversation History / Short-Term Memory)
*   **聊天**：实际的来回消息。
*   `[User]: 嗨！`
*   `[Agent]: 你好！有什么我可以帮你的吗？`
*   `[User]: 天气怎么样？`
*   **压缩**：较旧的历史记录可能会在此处被替换为摘要。

### 6. 草稿本 / 思考 (Scratchpad / Thoughts)
*   **思维链 (Chain-of-Thought)**：如果 Agent 正在“思考”，之前的推理步骤将包含在此处以指导最终答案。

## 上下文窗口管理

**上下文窗口** 是此组合文本的最大大小（以 Token 为单位）。
*   GPT-4: 8k 或 32k 或 128k。
*   Claude 3: 200k。
*   Llama 3: 8k/128k。

OpenClaw 动态管理此预算：
1.  **预留** 系统提示和工具的空间（必须始终适合）。
2.  **填充** 历史记录（最新的优先）。
3.  **注入** RAG 记忆（如果空间允许）。
4.  **截断** 或 **压缩** 最旧的历史记录（如果达到限制）。

## 调试上下文

要确切查看 Agent 看到的内容，您通常可以使用详细日志运行：

```bash
openclaw run --verbose
```

这将打印发送给 LLM 的完整提示，允许您检查记忆是否被检索，或者历史记录是否被正确截断。
